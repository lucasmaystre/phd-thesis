{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical efficiency of estimators\n",
    "\n",
    "This notebook computes the RMSE between ground-truth parameters and various estimators, using an experiment based on synthetically-generated data.\n",
    "It basically follows the experiment used to produce Figure 1 in Hajek et al., *Minimax-optimal Inference from Partial Rankings* (2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import choix\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "np.random.seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indep_break(full_rankings, size):\n",
    "    \"\"\"Break full rankings into independent & smaller (partial) ones.\"\"\"\n",
    "    data = list()\n",
    "    for r in full_rankings:\n",
    "        perm = np.random.permutation(n_items)\n",
    "        for i in range(0, n_items, size):\n",
    "            idx = np.sort(perm[i:i+size])\n",
    "            data.append(r[idx])\n",
    "    return data\n",
    "            \n",
    "def full_break(rankings):\n",
    "    \"\"\"Break (partial) rankings into all pairwise comparisons.\"\"\"\n",
    "    comparisons = list()\n",
    "    for ranking in rankings:\n",
    "        for i, winner in enumerate(ranking):\n",
    "            for loser in ranking[i+1:]:\n",
    "                comparisons.append((winner, loser))\n",
    "    return comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 4.0  # Dynamic range of the parameters\n",
    "log_n_items = 10  # Base-2 logarithm of number of items\n",
    "n_rankings = 64  # Number of full rankings generated.\n",
    "\n",
    "n_items = 2**log_n_items\n",
    "params = choix.generate_params(n_items, interval=interval)\n",
    "rankings = choix.generate_rankings(params, n_rankings, size=n_items)\n",
    "\n",
    "sizes = np.logspace(1, log_n_items, num=log_n_items, endpoint=True, base=2, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`res` will contain the experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    \"sizes\": sizes,\n",
    "    \"LSR\": list(),\n",
    "    \"ML\": list(),\n",
    "    \"GMM-F\": list(),\n",
    "    \"ML-F\": list(),\n",
    "    \"CRLB\": list(),\n",
    "    \"OLB\": 0.0,\n",
    "    \"XLB\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical efficiency of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "CPU times: user 15min 2s, sys: 5.21 s, total: 15min 7s\n",
      "Wall time: 15min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for size in sizes:\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    rk_data = indep_break(rankings, size)\n",
    "    # LSR.\n",
    "    est = choix.lsr_rankings(n_items, rk_data)\n",
    "    res[\"LSR\"].append(choix.rmse(params, est))\n",
    "    # Maximum-likelihood.\n",
    "    est = choix.ilsr_rankings(n_items, rk_data)\n",
    "    res[\"ML\"].append(choix.rmse(params, est))\n",
    "\n",
    "    pw_data = full_break(rk_data)\n",
    "    # GMM full-breaking.\n",
    "    est = choix.lsr_pairwise(n_items, pw_data)\n",
    "    res[\"GMM-F\"].append(choix.rmse(params, est))\n",
    "    # Maximum-likelihood full-breaking.\n",
    "    est = choix.ilsr_pairwise(n_items, pw_data)\n",
    "    res[\"ML-F\"].append(choix.rmse(params, est))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle lower bound\n",
    "\n",
    "$$\n",
    "n \\cdot \\text{MSE}\n",
    "    = \\inf_{\\hat{\\theta}} \\sup_{\\theta^\\star \\in \\Theta_b} E[\\lVert \\hat{\\theta} - \\theta^\\star \\rVert_2^2]\n",
    "    \\ge \\frac{1}{2 I(\\mu) + \\frac{2 \\pi^2}{b^2 (d_1 + d_2)}} \\frac{(n-1)^2}{mk}\n",
    "$$\n",
    "\n",
    "In our case:\n",
    "\n",
    "- $I(\\mu) = 1$ (given in the paper)\n",
    "- $n = n_{\\text{items}}$\n",
    "- $mk = n_{\\text{rankings}} \\cdot n_{\\text{items}}$\n",
    "- $d_1 = d_2 = n_{\\text{rankings}}$\n",
    "- $b = \\text{interval} / 2$\n",
    "\n",
    "and hence,\n",
    "\n",
    "$$\n",
    "\\text{MSE} =\n",
    "    \\frac{1}{2 + \\frac{4 \\pi}{\\text{interval}^2 n_{\\text{rankings}}}}\n",
    "    \\frac{(n_{\\text{items}} - 1)^2}{n_{\\text{items}}^2 n_{\\text{rankings}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 / (2 + 4 * math.pi / (interval**2 * n_rankings))\n",
    "b = (n_items - 1)**2 / (n_items**2 * n_rankings)\n",
    "res[\"OLB\"] = np.sqrt(a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramér-Rao lower bound\n",
    "\n",
    "This lower bound is only valid for *unbiased* estimators.\n",
    "\n",
    "$$\n",
    "n \\cdot \\text{MSE}\n",
    "    = \\inf_{\\hat{\\theta} \\in \\mathcal{U}} \\sup_{\\theta^\\star \\in \\Theta_b} E[\\lVert \\hat{\\theta} - \\theta^\\star \\rVert_2^2]\n",
    "    \\le \\left( 1 - \\frac{1}{k} \\sum_{\\ell=1}^k \\frac{1}{\\ell} \\right)^{-1} \\frac{(n-1)^2}{mk}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for size in sizes:\n",
    "    H_k = sum(1.0 / ell for ell in range(1, size+1))\n",
    "    a = 1 / (1 - H_k / size)\n",
    "    crlb = np.sqrt(a * (n_items - 1)**2 / (n_items**2 * n_rankings))\n",
    "    res[\"CRLB\"].append(crlb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can furthermore simplify the Cramér-Rao lower-bound as follows.\n",
    "\n",
    "$$\n",
    "\\left( 1 - \\frac{1}{k} \\sum_{\\ell=1}^k \\frac{1}{\\ell} \\right)^{-1} \\frac{(n-1)^2}{mk}\n",
    "    \\le \\frac{(n-1)^2}{mk}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"XLB\"] = np.sqrt((n_items - 1)**2 / (n_items**2 * n_rankings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/statistical-efficiency.pickle\", \"wb\") as f:\n",
    "    pickle.dump(res, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
