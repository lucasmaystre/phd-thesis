\newcommand{\D}[2]{\ensuremath{\mathcal{D}_{#1 \succ #2}}}

\section{Stationary Points of the Log-Likelihood}

In this section, we briefly explain why the log-likelihood in Luce's model has a unique stationary point, that at the ML estimate.
Recall that we assume that the comparison graph $G_{\mathcal{D}}$ is strongly connected.
The log-likelihood is given by
\begin{align}
\label{fix:eq:loglik}
\log \mathcal{L}(\bm{\pi} \mid \mathcal{D}) = \sum_{\ell = 1}^d \left( \log \pi_\ell - \log{\sum_{j \in A_\ell} \pi_j} \right).
\end{align}
This function is not concave in $\bm{\pi}$; however, this does not preclude the existence of a unique stationary point.
Letting $\pi_i = e^{\theta_i}$, we write the reparametrized log-likelihood as
\begin{align*}
\log \mathcal{L}(\bm{\pi}(\bm{\theta}) \mid \mathcal{D}) = \sum_{\ell = 1}^d \left( \theta_\ell - \log{\sum_{j \in A_\ell} e^{\theta_j}} \right),
\end{align*}
which is strictly concave in $\bm{\theta}$ and therefore admits a unique stationary point, at the maximum of the function.
Denote this maximum by $\hat{\bm{\theta}}$.
The partial derivative of the log-likelihood with respect to $\pi_\ell$ is
\begin{align}
\frac{\partial \log \mathcal{L}}{\partial \pi_\ell}
  = \frac{\partial \log \mathcal{L}}{\partial \theta_i} \cdot \frac{\partial \theta_i}{\partial \pi_i}
  = \frac{\partial \log \mathcal{L}}{\partial \theta_i} \cdot \frac{1}{\pi_i}.
\end{align}
As $1/\pi_i$ is strictly positive, the partial derivative vanishes only at $\hat{\pi}_i = e^{\hat{\theta}_i}$.
In conclusion, $\hat{\bm{\pi}}$ is the unique ML estimate, as well as the only stationary point.


\section{Bound on Error Rate of ML Estimate}

We use the analytical framework of \citet{negahban2017rank} to bound the error rate of the ML estimator in the case where
\begin{enuminline}
\item the data is in the form of pairwise comparisons and
\item for each pair under comparison, we observe exactly $k$ outcomes.
\end{enuminline}

Let $G = (V, E)$ be an undirected graph where $V = \{ 1, \ldots, n \}$ and $(i, j) \in E$ if $i$ and $j$ have been compared.
Let $d_{\min}$ and $d_{\max}$ be the minimum and maximum degree of a node in $G$, respectively.
Let $\gamma$ be the spectral gap of a simple random walk on $G$;
intuitively, the larger the spectral gap is, the faster the convergence to the stationary distribution is.
For each $(i, j) \in E$ we observe $k$ comparisons generated from ground truth parameters $\bm{\pi}^*$.
Let $A_{ji}$ denote the number of times $i$ wins against $j$ and $a_{ji} = A_{ji} / k$ the ratio of wins of $i$ over $j$.
We say that an event $X$ occurs with high probability if $\mathbf{P}(X) \ge 1 - c / n^\alpha$ for $c, \alpha$ fixed.

\begin{theorem}
\label{fix:thm:mlbound}
For $k \ge 4C^2 (1 + (b^6 \kappa^2 / (d_{\max} \gamma^2)) \log n)$, the error on the ML estimate $\mlpi$ satisfies w.h.p.
\begin{align}
\frac{\Vert \mlpi - \bm{\pi}^* \Vert_2}{\Vert \bm{\pi}^* \Vert_2} < C \frac{b^{7/2} \kappa}{\gamma} \sqrt{\frac{\log n}{kd_{\max}}},
\end{align}
where $C$ is a constant, $b = \max_{i,j} \pi^*_i / \pi^*_j$ and $\kappa = d_{\max} / d_{\min}$.
\end{theorem}

\begin{proof}
The ML estimate can be interpreted as the stationary distribution of the discrete-time Markov chain
\begin{align}
\label{fix:eq:mlchain}
  \widehat{P}_{ij} =
  \begin{dcases}
    \epsilon \frac{a_{ij}}{\hat{\pi}_i + \hat{\pi}_j}                    & \text{if } i \ne j, \\
    1 - \epsilon \sum_{l \ne i} \frac{a_{il}}{\hat{\pi}_i + \hat{\pi}_l} & \text{if } i = j.
  \end{dcases}
\end{align}
The factor $\epsilon = \hat{\pi}_{\min} / d_{\max}$ ensures that $\widehat{P}$ is stochastic.
Given this matrix, it is straightforward to analyze the $\mlpi$ by using the methods developed for Rank Centrality (RC);
the proof essentially follows that of Theorem~1 of \citet{negahban2017rank}.
Let $P^*$ be the ideal Markov chain, when  $a_{ij} = \pi^*_j / (\pi^*_i + \pi^*_j)$, i.e., the ratios are noiseless.
The key observation is to note that the stationary distribution of $P^*$ is $\bm{\pi}^*$, the true model parameters.
By bounding $\Vert \widehat{P} - P^* \Vert_2$ and $1 - \lambda_{\max}(P^*)$, we can bound the error on the stationary distribution of $P^*$.
For the former, a straightforward application of the proof in the RC case suffices.
For the latter, in the application of the comparison theorem, the lower bound on $\min_{i,j} \pi^*_i P^*_{ij}$ changes by a factor of $1/(2b)$.
This is due to the additional factor $\hat{\pi}_{\min} / (\hat{\pi}_i + \hat{\pi}_j)$ in the off-diagonal entries of $P^*$.
\end{proof}

If the graph of comparisons $G$ is an expander, then $\gamma = O(1)$.
Furthermore, if $d_{\max} \propto d_{\min}$, then $\kappa = O(1)$.
A realization of the $G(n, p)$ random graph satisfies these two constraints with high probability as long as $p = \omega(\log n / n)$.
It follows that if $\omega(n \log n)$ comparison pairs are chosen uniformly at random and $k = O(1)$ outcomes are observed for each pair, the error goes to zero as $n$ increases.

\citet{hajek2014minimax} recently proved a more general version of our result, using a different analytical technique.
Their bound is qualitatively similar, but also applies to multiway rankings and heterogeneous number of comparisons.

\section{Derivation for the Rao--Kupper Model}

We consider a model that was proposed by Rao and Kupper in 1967 \citep{rao1967ties}.
This model extends the Bradley--Terry model in that a comparison between two items can result in a tie.
Letting $\alpha \in [1, \infty)$, the probabilities of $i$ winning over and tying with $j$, respectively, are given as follows.
\begin{align*}
p(i \succ j) &= \frac{\pi_i}{\pi_i + \alpha \pi_j}, \\
p(i \leftrightarrow j) &= \frac{\pi_i \pi_j(\alpha^2 - 1)}{(\pi_i + \alpha\pi_j)(\alpha \pi_i + \pi_j)}.
\end{align*}
This model is useful for e.g., chess, where a significant fraction of comparison outcomes do not result in either a win or a loss.

We assume that the parameter $\alpha$ is fixed, and derive an expression of the ML estimate $\mlpi$.
Let $A_{ji}$ be the number of times $i$ wins over $j$, and $T_{ij} = T_{ji}$ be the number of ties between $i$ and $j$.
The log-likelihood can be written as
\begin{align}
\log \mathcal{L} &=
  \sum_i \sum_{j \ne i}
  A_{ji} \left( \log(\pi_i) - \log(\pi_i + \alpha \pi_j) \right) \\
    &+ \sum_i \sum_{j > i} \nonumber
    T_{ij} ( \log(\pi_i) + \log(\pi_j) + \log(\alpha^2 - 1) \\
    & \qquad \qquad {} - \log(\pi_i + \alpha \pi_j) - \log(\alpha \pi_i + \pi_j) ). \nonumber
\end{align}
The log-likelihood function is strictly concave and the model admits a unique ML estimate $\mlpi$.
The optimality condition $\nabla_{\mlpi} \log \mathcal{L} = 0$ implies
\begin{align}
  \frac{\partial \log \mathcal{L}}{\partial \hat{\pi}_i}
  = &\sum_{j \ne i} A_{ji} \left( \frac{1}{\hat{\pi}_i} - \frac{1}{\hat{\pi}_i + \alpha \hat{\pi}_j} \right)
    - A_{ij} \frac{\alpha}{\alpha \hat{\pi}_i + \hat{\pi}_j} \\
  & \qquad {} + T_{ij} \left( \frac{1}{\hat{\pi}_i} - \frac{1}{\hat{\pi}_i + \alpha \hat{\pi}_j} - \frac{\alpha}{\alpha \hat{\pi}_i + \hat{\pi}_j}\right) = 0 \\
  \iff & \sum_{j \ne i} A_{ji} \frac{\alpha \hat{\pi}_j}{\hat{\pi}_i + \alpha \hat{\pi}_j}
    - A_{ij} \frac{\alpha \hat{\pi}_i}{\alpha \hat{\pi}_i + \hat{\pi}_j} \\
  & \qquad {} + T_{ij} \frac{\alpha \hat{\pi}_j^2 - \alpha \hat{\pi}_i^2}{(\hat{\pi}_i + \alpha \hat{\pi}_j)(\alpha \hat{\pi}_i + \hat{\pi}_j)} = 0 \\
  \iff & \sum_{j \ne i} \frac{A_{ji} + T_{ji}\tfrac{\hat{\pi}_j}{\alpha \hat{\pi}_i + \hat{\pi}_j}}{\hat{\pi}_i + \alpha \hat{\pi}_j} \hat{\pi}_j
    - \frac{A_{ij} + T_{ij}\tfrac{\hat{\pi}_i}{\hat{\pi}_i + \alpha \hat{\pi}_j}}{\alpha \hat{\pi}_i + \hat{\pi}_j} \hat{\pi}_i = 0.
\end{align}
Therefore, the ML estimate is the stationary distribution of a Markov chain with transition rates
\begin{align}
\lambda_{ij} = \frac{A_{ij} + T_{ij}\tfrac{\hat{\pi}_i}{\hat{\pi}_i + \alpha \hat{\pi}_j}}{\alpha \hat{\pi}_i + \hat{\pi}_j}.
\end{align}
The extension of LSR and I-LSR to the Rao--Kupper model given these transition rates is straightforward.



\section{Finding the Stationary Distribution}

A set of transition rates $[\lambda_{ij}]$ that satisfy the strong connectivity assumption yields a unique stationary distribution $\bm{\pi}$.
In practice, finding this stationary distribution can be implemented in various ways.
We distinguish implementations based on whether they consider a continuous-time or a discrete-time perspective on Markov chains.

\paragraph{Continuous-Time Perspective}
We consider the infinitesimal generator matrix $Q$, where $Q_{ij} \doteq \lambda_{ij}$ and $Q_{ii} \doteq - \sum_{j} \lambda_{ij}$.
The stationary distribution satisfies $\bm{\pi} Q = 0$; this is essentially a matrix formulation of the global balance equations.
Therefore, one approach to finding the steady-state distribution is to compute the rank-$1$ left nullspace of $Q$.
This can be done e.g., by LU decomposition, a basic linear-algebra primitive.
In the dense case, the running time of a typical implementation is $O(n^3)$, but highly optimized parallel implementations such as that provided by LAPACK \citep{anderson1999lapack} are commonly available.
In the sparse case, LU decomposition can be done significantly faster using adapted algorithms, such as that of \citet{demmel1999supernodal}.

\paragraph{Discrete-Time Perspective}
Let $\epsilon < 1 / \max_i |Q_{ii}|$, then $P = I + \epsilon Q$ is the transition matrix of a discrete-time Markov chain that satisfies $\bm{\pi} P = \bm{\pi}$.
In this case, finding the steady-state distribution is equivalent to finding the left eigenvector associated to the leading eigenvalue of the transition matrix $P$.
This is also a well-studied linear algebra problem for which plenty of efficient, off-the-shelf algorithms exist.
For example, power iteration methods can find the eigenvector in a few (sparse) matrix multiplications.
Beyond these well-known algorithms, the recently proposed randomized approach of \citet{halko2011finding} enables us to scale to truly large problem sizes ($n$ is $O(10^6)$ or more.)

For our experiments, we have implemented LSR and I-LSR using a dense LU factorization of the generator matrix.
The Python code, which relies on the \texttt{numpy} and \texttt{scipy} libraries\footnote{
See: \url{http://www.scipy.org/}.
}, is displayed in Figure~\ref{fix:lst:implementation}

%\lstset{
%  language=Python,
%  basicstyle=\ttfamily\footnotesize,         % Teletype font.
%  showstringspaces=false,       % Don't put underscores in place of spaces.
%  numberstyle=\ttfamily, % Numbers in gray (+ teletype font).
%  numbers=left,                 % Show line numbers on the left.
%  numbersep=5pt,                % Give some space to those poor line numbers.
%  xleftmargin=15pt,             % But don't put them in the margin either.
%  %columns=fixed,               % No idea what this is for.
%}
\begin{figure}
\begin{lstlisting}
import numpy as np
import scipy.linalg as spl

def weighted_lsr(n, rankings, weights):
    chain = np.zeros((n, n), dtype=float)
    for ranking in rankings:
        sum_weights = sum(weights[x] for x in ranking)
        for i, winner in enumerate(ranking):
            val = 1.0 / sum_weights
            for loser in ranking[i+1:]:
                chain[loser, winner] += val
            sum_weights -= weights[winner]
    chain -= np.diag(chain.sum(axis=1))
    return statdist(chain)

def statdist(chain):
    lu, piv = spl.lu_factor(generator.T)
    res = spl.solve_triangular(lu[:-1,:-1], -lu[:-1,-1])
    res = np.append(res, 1.0)
    return res / res.sum()
\end{lstlisting}
\caption{
Python implementation of one iteration of I-LSR.
}
\label{fix:lst:implementation}
\end{figure}

\section{Experimental Procedure}

We give a few additional details on the procedure that we followed for the experiments of Section~4 in the main paper.
All experiments were run on a machine with a quad-core 2.0 GHz Haswell processor, and 16GB of RAM, running Mac OS X 10.9.
For LSR and I-LSR, we used a slightly adapted version the code presented in Figure~\ref{fix:lst:implementation}.
We implemented the Rank Centrality (RC), GMM-F \citep{azari2013generalized}, and MM \citep{hunter2004mm} algorithms in Python.
For Newton-Raphson, we implemented our choice model on top of the popular \texttt{statsmodels} Python library\footnote{
See: \url{http://statsmodels.sourceforge.net/}
} that provides a Newton-Raphson solver.
For completeness, the Python source code containing all the functions we used is provided as a separate file in the supplementary material.
We have compared our implementation of the MM algorithm to that of \citeauthor{hunter2004mm} written in Matlab\footnote{
See: \url{http://sites.stat.psu.edu/~dhunter/code/btmatlab/}
}, and observed that ours has comparable running time.

For the chess dataset, we use the Rao--Kupper model and set the parameter $\alpha = \sqrt{2}$.
Note that this parameter could also be estimated from the data, however in our experiments we focus on the performance of algorithms for estimating $\mlpi$.
