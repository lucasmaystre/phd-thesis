%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{rs:sec:intro}

Whereas pairwise comparison models and related inference algorithms have been extensively studied, the issue of \emph{which pairwise comparisons to query} has received significantly less attention from the research community.
To understand the potential benefits of adaptively selecting samples, consider the case where comparison outcomes are noiseless, i.e., consistent with a linear order on a set of $N$ items.
If pairs of items are selected at random, it is necessary to collect \BigOmega{N^2} comparisons to recover the ranking \citep{alon1994linear}.
In contrast, by using an efficient sorting algorithm, \BigO{N \log N} adaptively chosen comparisons are sufficient.
In this chapter, we demonstrate that sorting algorithms can also be helpful in the \emph{noisy} setting, where some comparison outcomes are inconsistent with the ranking: despite errors, sorting algorithms tend to select informative samples.
We focus on the Bradley--Terry (BT) model, that captures the intuitive notion that some pairs of items are easy to compare, but some are more difficult (c.f. Section~\ref{in:sec:btmodel}).

First, we study the output of a single execution of Quicksort when comparison outcomes are generated from a BT model, under the assumption that the distance between adjacent parameters is (stochastically) uniform across the ranking.
We measure the quality of a ranking estimate by its displacement with respect to the ground truth, i.e., the sum of rank differences.
We show that Quicksort's output is a good approximation to the ground-truth ranking: no method comparing every pair of items at most once can do better (up to constant factors).
Furthermore, we show that by aggregating \BigO{\log^5 N} independent runs of Quicksort, it is possible to recover the exact rank for all but a vanishing fraction of the items.
These theoretical results suggest that adaptive sampling is able to bring a substantial acceleration to the learning process.

Second, we propose a practical active-learning (AL) strategy that consists of repeatedly sorting the items.
We evaluate our sorting-based method on three datasets and compare it to existing AL methods.
We observe that \emph{all} the strategies that we consider lead to better ranking estimates noticeably faster than random sampling.
However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption \citep{schein2007active}.
In this regard, sorting-based AL stands out, as
\begin{enuminline}
\item it is computationally-speaking as inexpensive as random sampling, 
\item it is trivial to implement, and
\item it requires no tuning of hyperparameters.
\end{enuminline}

\paragraph{Outline of the Chapter}
After concluding this section with some preliminaries, we review related literature in Section~\ref{rs:sec:relwork}.
Next, in Section~\ref{rs:sec:theory}, we study the displacement of Quicksort's output under noisy comparisons.
In Section~\ref{rs:sec:experiments}, we empirically evaluate several AL strategies on three datasets.
For clarity of presentation, we defer some proofs to Section~\ref{rs:sec:proofs}.

\subsection{Preliminaries and Notation}

Without loss of generality, we assume that the $N$ items are enumerated by increasing preference\footnote{
This convention greatly simplifies the notation throughout the chapter, but differs from that used in most of the preference-learning literature.
In this chapter, the item with rank $1$ is the \emph{worst}.}, i.e., $i < j$ means that $j$ is (in expectation) preferred to $i$ for all $i, j \in [N]$.
When $j$ is preferred to $i$ as a result of a pairwise comparison, we denote the observation by $i \prec j$.
If $i < j$, we say that $i \prec j$ is a \emph{consistent} outcome and $j \prec i$ an \emph{inconsistent} (incorrect) outcome.
We denote by $\BT(\bm{\theta})$ a Bradley--Terry model with parameters $\bm{\theta} = [\theta_1 \ \cdots \ \theta_N ]^\Tr \in \mathbf{R}^N$.
A ranking $\sigma$ is a function that maps an item to its rank, i.e., $\sigma(i) =$ rank of item $i$.
The (ground-truth) identity ranking is denoted by \Id, i.e. $\Id(i) = i$.
To measure the quality of a ranking $\sigma$ with respect to the ground-truth, we consider the \emph{displacement}
\begin{align*}
\Disp{\sigma} = \sum_{i=1}^N | \sigma(i) - i |,
\end{align*}
also known as Spearman's footrule distance.
Another metric widely used in practice is the Kendall--Tau distance, defined as
$K(\sigma) = \sum_{i < j} \Indic{\sigma(i) > \sigma(j)}$.
\citet{diaconis1977spearman} show that both metrics are equivalent up to a factor of two, i.e.,
\begin{align*}
\Disp{\sigma} / 2 \le K(\sigma) \le \Disp{\sigma}.
\end{align*}
Hence, bounds on \Disp{\sigma} also hold for $K(\sigma)$ up to constant factors.
Finally, we say that an event $A$ holds \emph{with high probability} if $\Prob{A} \to 1$ as $N \to \infty$.
For a random variable $X$ and a sequence of numbers $a_N$, we say that $X = \BigO{a_N}$ with high probability if $\Prob{\Abs{X} \le c a_N} \to 1$ as $N \to \infty$ for some constant $c$ that does not depend on $N$.
