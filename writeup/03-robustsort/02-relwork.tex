%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{rs:sec:relwork}

\paragraph{Passive Setting}
Recently, there have been a number of results on the sample complexity of the BT model, based on the assumption that all pairs of items are chosen \emph{before} any comparison outcome is revealed
\citep{negahban2012iterative, hajek2014minimax, rajkumar2014statistical, vojnovic2016parameter}.
In general, these results reveal that choosing pairs of items uniformly at random is essentially optimal.
Furthermore, they suggest that the ranking induced by the BT model cannot be recovered with less than \BigOmega{N^2} comparisons.
Our work shows that by \emph{adaptively} selecting pairs based on observed outcomes, we observe substantial gains.

\paragraph{Active Preference Learning}
AL approaches for learning a ranking from noisy comparison outcomes have been studied under various assumptions.
\citet{braverman2008noisy} examine a model where outcomes of pairwise comparisons are flipped with a small, constant probability.
\citet{ailon2012active} considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST).
These theoretical studies imply, in their respective settings, that \BigO{N \log^k N} comparison outcomes are enough to recover a near-optimal ranking, for some $k \in \mathbf{N}_{>0}$.
%They design an algorithm that recovers the maximum-likelihood ranking in polynomial-time using only \BigO{n \log n} comparisons, but its running time is impractical.
\citet{jamieson2011active} propose an efficient active-ranking algorithm that is applicable if items can be embedded in $\mathbf{R}^D$ (e.g., using $D$ features) and assuming that admissible rankings satisfy some geometric constraints.
\citet{wang2014active} study a collaborative preference-learning problem (each user is modeled by a different BT model) and show that a variant of uncertainty sampling---a well-known AL strategy---works well for their problem.
Here, we assume that we do not have access to item features and that comparison outcomes follow a single BT model.

\paragraph{Bayesian Methods}
From a practical standpoint, Bayesian methods provide an effective way to select informative samples \citep{mackay1992bayesian}.
However, they can be difficult to scale if the number of items is large.
Work on Bayesian active preference learning includes
\citet{chu2005extensions}, \citet{houlsby2012collaborative}, \citet{salimans2012collaborative} and \citet{chen2013pairwise}.
%While the methods in these papers generally assume that outcomes follow Thurstone's model \citep{thurstone1927law}, they are easy to extend to the BT model.
We compare our AL strategy to these methods in Section~\ref{rs:sec:experiments}.

\paragraph{Multi-Armed Bandit}
The \emph{dueling bandit} problem \citep{yue2009karmed} is somewhat related to our work.
In this problem, the goal is to identify the best item, based on noisy comparison outcomes, using as few adaptively chosen samples as possible.
Two recent papers also extend the problem to that of recovering the entire ranking (instead of only the top element).
The work of \citet{szorenyi2015online} is the closest to ours, as it also uses the BT model.
They show that a quasilinear number of comparisons is sufficient for recovering the true ranking (under some conditions on $\bm{\theta}$), a result that is similar to our Theorem~\ref{rs:thm:multidisp}.
\citet{heckel2016active} investigate a non-parametric model and develop some theoretical guarantees.
In contrast to these works, we study practical comparison budgets: we give theoretical guarantees for the output obtained from a single call to Quicksort, and in our experiments we never exceed $\approx 10$ calls.

\paragraph{Quicksort}
The Quicksort algorithm \citep{hoare1962quicksort} is one of the most widely studied sorting procedures.
Quicksort has been shown to produce useful rankings beyond classic sorting problems.
For example, \citet{ailon2008aggregating} show that Quicksort produces (in expectation) a $3$-approximation to the MFAST problem.
Quicksort combined with BT comparison outcomes has also been proposed as a probabilistic ranking model \citep{ailon2008reconciling}.
We take advantage of some of the properties of this ranking model in order to derive the theoretical results of Section~\ref{rs:sec:theory}.
